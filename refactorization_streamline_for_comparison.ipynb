{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and dependencies\n",
    "import os\n",
    "import requests\n",
    "import mysql.connector\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from mysql.connector import Error\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api endpoints and keys\n",
    "TICKETMASTER_API_KEY = os.getenv('TICKETMASTER_API_KEY')\n",
    "TOMORROW_API_KEY = os.getenv('TOMORROW_API_KEY')\n",
    "\n",
    "TICKETMASTER_Events_API_Endpoint = \"https://app.ticketmaster.com/discovery/v2/events.json\"\n",
    "# Note: Austinâ€™s weather API endpoint will be constructed via parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL connection parameters\n",
    "MYSQL_HOST = os.getenv('MYSQL_HOST')\n",
    "MYSQL_USER = os.getenv('MYSQL_USER')\n",
    "MYSQL_PASSWORD = os.getenv('MYSQL_PASSWORD')\n",
    "MYSQL_DATABASE = os.getenv('MYSQL_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle the database connection\n",
    "def get_db_connection():\n",
    "    \"\"\"Establish and return a MySQL database connection.\"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=MYSQL_HOST,\n",
    "            user=MYSQL_USER,\n",
    "            password=MYSQL_PASSWORD,\n",
    "            database=MYSQL_DATABASE\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            print(\"Connected to MySQL database\")\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(f\"Database connection error: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract full datetime from event 'dates' field\n",
    "def extract_event_datetime(dates):\n",
    "    \"\"\"\n",
    "    Extract a full datetime string from the Ticketmaster API's dates field.\n",
    "    Expects 'dates' to be a dict with a 'start' key that contains 'localDate'\n",
    "    and optionally 'localTime'. If 'localTime' is missing, defaults to \"12:00:00\".\n",
    "    Returns a string formatted as 'YYYY-MM-DD HH:MM:SS' or None if not available.\n",
    "    \"\"\"\n",
    "    if isinstance(dates, dict) and 'start' in dates:\n",
    "        start_info = dates['start']\n",
    "        local_date = start_info.get('localDate')\n",
    "        # Attempt to get the localTime; if missing, default to noon\n",
    "        local_time = start_info.get('localTime', \"12:00:00\")\n",
    "        if local_date:\n",
    "            try:\n",
    "                dt = datetime.strptime(f\"{local_date} {local_time}\", \"%Y-%m-%d %H:%M:%S\")\n",
    "                return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing datetime: {e}\")\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cynthias events and venues code in a function\n",
    "def get_events_and_venues_data():\n",
    "    \"\"\"\n",
    "    Pull Ticketmaster events for San Diego for the next 7 days,\n",
    "    then parse and return two DataFrames:\n",
    "      - events_df: event_id, event_name, start_date, venue_id, event_category\n",
    "      - venues_df: venue_id, venue_name, venue_city, venue_state, venue_country, venue_location\n",
    "    \"\"\"\n",
    "    # define date range: today to 6 days later (7 days total)\n",
    "    today = datetime.today()\n",
    "    six_days_later = today + timedelta(days=5)\n",
    "    start_date = today.strftime('%Y-%m-%dT00:00:00Z')\n",
    "    end_date = six_days_later.strftime('%Y-%m-%dT23:59:59Z')\n",
    "    \n",
    "    params = {\n",
    "        \"apikey\": TICKETMASTER_API_KEY,\n",
    "        \"city\": \"San Diego\",\n",
    "        \"size\": 200,\n",
    "        \"startDateTime\": start_date,\n",
    "        \"endDateTime\": end_date\n",
    "    }\n",
    "    \n",
    "    print(\"Requesting Ticketmaster events...\")\n",
    "    response = requests.get(TICKETMASTER_Events_API_Endpoint, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Ticketmaster API Error: {response.status_code}, {response.text}\")\n",
    "    \n",
    "    data = response.json()\n",
    "    events = data.get(\"_embedded\", {}).get(\"events\", [])\n",
    "    if not events:\n",
    "        print(\"No events found.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # convert list of events to dataframe\n",
    "    df = pd.DataFrame(events)\n",
    "    \n",
    "    # extract event details\n",
    "    df['event_id'] = df['id']\n",
    "    df['event_name'] = df['name']\n",
    "    # Use 'dates.start.localDate' as our start_date (could be refined to include time if available)\n",
    "    df['start_date'] = df['dates'].apply(extract_event_datetime)\n",
    "    df['event_category'] = df['classifications'].apply(lambda x: x[0]['segment']['name'] if isinstance(x, list) and len(x) > 0 and 'segment' in x[0] else None)\n",
    "    \n",
    "    # extract Venue details\n",
    "    df['venue_id'] = df['_embedded'].apply(lambda x: x['venues'][0]['id'] if isinstance(x, dict) and 'venues' in x else None)\n",
    "    df['venue_name'] = df['_embedded'].apply(lambda x: x['venues'][0]['name'] if isinstance(x, dict) and 'venues' in x else None)\n",
    "    df['venue_city'] = df['_embedded'].apply(lambda x: x['venues'][0]['city']['name'] if isinstance(x, dict) and 'venues' in x else None)\n",
    "    df['venue_state'] = df['_embedded'].apply(lambda x: x['venues'][0]['state']['stateCode'] if isinstance(x, dict) and 'venues' in x and 'state' in x['venues'][0] else None)\n",
    "    df['venue_country'] = df['_embedded'].apply(lambda x: x['venues'][0]['country']['countryCode'] if isinstance(x, dict) and 'venues' in x else None)\n",
    "    # combine latitude and longitude into one \"venue_location\" column (as requested)\n",
    "    df['venue_location'] = df['_embedded'].apply(\n",
    "        lambda x: f\"{x['venues'][0]['location']['latitude']},{x['venues'][0]['location']['longitude']}\" \n",
    "        if isinstance(x, dict) and 'venues' in x and 'location' in x['venues'][0] else None\n",
    "    )\n",
    "    \n",
    "    # create dataframes for events and venues\n",
    "    events_df = df[['event_id', 'event_name', 'start_date', 'venue_id', 'event_category']]\n",
    "    venues_df = df[['venue_id', 'venue_name', 'venue_city', 'venue_state', 'venue_country', 'venue_location']].drop_duplicates()\n",
    "    \n",
    "    print(f\"Pulled {len(events_df)} events from API.\")\n",
    "    return events_df, venues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting cynthias events and venues data into the database\n",
    "def insert_events_and_venues(events_df, venues_df, connection):\n",
    "    \"\"\"\n",
    "    Insert venues and events data into MySQL.\n",
    "    Before insertion, delete any past events.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # delete past events (using 'start_date' column)\n",
    "        delete_query = \"DELETE FROM events WHERE start_date < CURDATE();\"\n",
    "        cursor.execute(delete_query)\n",
    "        print(f\"Deleted {cursor.rowcount} past events.\")\n",
    "        connection.commit()\n",
    "        \n",
    "        # insert/update venues\n",
    "        insert_venue_query = \"\"\"\n",
    "        INSERT INTO venues (venue_id, name, city, state, country, location)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE \n",
    "            name = VALUES(name),\n",
    "            city = VALUES(city),\n",
    "            state = VALUES(state),\n",
    "            country = VALUES(country),\n",
    "            location = VALUES(location);\n",
    "        \"\"\"\n",
    "        for _, row in venues_df.iterrows():\n",
    "            cursor.execute(insert_venue_query, tuple(row))\n",
    "        connection.commit()\n",
    "        print(\"Venues inserted/updated successfully.\")\n",
    "        \n",
    "        # insert/update events\n",
    "        # note: our events table expects columns: event_id, name, start_date, venue_id, and a category column.\n",
    "        insert_event_query = \"\"\"\n",
    "        INSERT INTO events (event_id, name, start_date, venue_id, category)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE \n",
    "            name = VALUES(name),\n",
    "            start_date = VALUES(start_date),\n",
    "            venue_id = VALUES(venue_id),\n",
    "            category = VALUES(category);\n",
    "        \"\"\"\n",
    "        for _, row in events_df.iterrows():\n",
    "            cursor.execute(insert_event_query, tuple(row))\n",
    "        connection.commit()\n",
    "        print(\"Events inserted/updated successfully.\")\n",
    "        \n",
    "        cursor.close()\n",
    "    except Error as e:\n",
    "        print(f\"Error inserting events/venues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# austins weather code in a function\n",
    "def get_weather_forecast_data():\n",
    "    \"\"\"\n",
    "    Pull hourly weather forecasts for San Diego for the next week.\n",
    "    Process the data into a DataFrame that matches the new weather_forecasts schema.\n",
    "    Schema includes:\n",
    "        forecast_time (DATETIME),\n",
    "        forecast_temperature (DECIMAL),\n",
    "        forecast_temp_apparent (DECIMAL),\n",
    "        forecast_humidity (DECIMAL),\n",
    "        rain_intensity (DECIMAL),\n",
    "        forecast_winds (DECIMAL),\n",
    "        weather_code (INT),\n",
    "        weather_icon (TEXT)\n",
    "    \"\"\"\n",
    "    # define date range (today to 6 days later)\n",
    "    today = datetime.today()\n",
    "    next_7_days = today + timedelta(days=5)\n",
    "    start_date = today.strftime('%Y-%m-%dT00:00:00Z')\n",
    "    end_date = next_7_days.strftime('%Y-%m-%dT23:59:59Z')\n",
    "    \n",
    "    print(\"Requesting Tomorrow.io weather forecast data...\")\n",
    "    params = {\n",
    "        \"apikey\": TOMORROW_API_KEY,\n",
    "        \"location\": \"32.7157,-117.1611\",\n",
    "        \"startDateTime\": start_date,\n",
    "        \"endDateTime\": end_date\n",
    "    }\n",
    "    # construct endpoint url (Austinâ€™s hard-coded an endpoint; here we use it)\n",
    "    endpoint = \"https://api.tomorrow.io/v4/weather/forecast\"\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Weather API call failed: {response.status_code}, {response.text}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # parse the weather forecast data.\n",
    "    # assume the JSON structure contains an hourly timeline under data['timelines']['hourly']\n",
    "    weather_data = []\n",
    "    # define mapping from weather code to icon filename (as provided)\n",
    "    weather_code_icons = {\n",
    "        1100: \"mostly_clear_day.svg\",\n",
    "        1101: \"partly_cloudy_day.svg\",\n",
    "        1102: \"mostly_cloudy.svg\",\n",
    "        1000: \"clear_day.svg\",\n",
    "        1001: \"cloudy.svg\",\n",
    "        2100: \"fog_light.svg\",\n",
    "        2000: \"fog.svg\",\n",
    "        4000: \"drizzle.svg\",\n",
    "        4200: \"rain_light.svg\",\n",
    "        4001: \"rain.svg\",\n",
    "        4201: \"rain_heavy.svg\",\n",
    "        6000: \"freezing_drizzle.svg\",\n",
    "        6200: \"freezing_rain_light.svg\",\n",
    "        6001: \"freezing_rain.svg\",\n",
    "        6201: \"freezing_rain_heavy.svg\",\n",
    "        8000: \"tstorm.svg\",\n",
    "    }\n",
    "    base_url = \"https://raw.githubusercontent.com/Tomorrow-IO-API/tomorrow-weather-codes/master/V1_icons/color/\"\n",
    "    \n",
    "    # loop over hourly forecasts\n",
    "    try:\n",
    "        intervals = data['timelines']['hourly']\n",
    "    except KeyError:\n",
    "        print(\"Unexpected weather API response structure.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for interval in intervals:\n",
    "        # each interval should have a 'time' and 'values'\n",
    "        time_str = interval.get('time')\n",
    "        # convert time string (assumed in ISO format) to MySQL DATETIME string format\n",
    "        forecast_time = pd.to_datetime(time_str, utc=True).tz_convert(\"America/Los_Angeles\").strftime('%Y-%m-%d %H:%M:%S')\n",
    "        values = interval.get('values', {})\n",
    "        forecast_temperature = values.get('temperature')\n",
    "        forecast_temp_apparent = values.get('temperatureApparent')\n",
    "        forecast_humidity = values.get('humidity')\n",
    "        rain_intensity = values.get('rainIntensity')\n",
    "        forecast_winds = values.get('windSpeed')\n",
    "        weather_code = values.get('weatherCode')\n",
    "        #get icon based on weather_code mapping\n",
    "        icon_filename = weather_code_icons.get(weather_code, \"default.png\")\n",
    "        weather_icon = f\"{base_url}{icon_filename}\"\n",
    "        \n",
    "        weather_data.append({\n",
    "            'forecast_time': forecast_time,\n",
    "            'forecast_temperature': forecast_temperature,\n",
    "            'forecast_temp_apparent': forecast_temp_apparent,\n",
    "            'forecast_humidity': forecast_humidity,\n",
    "            'rain_intensity': rain_intensity,\n",
    "            'forecast_winds': forecast_winds,\n",
    "            'weather_code': weather_code,\n",
    "            'weather_icon': weather_icon\n",
    "        })\n",
    "    \n",
    "    weather_df = pd.DataFrame(weather_data)\n",
    "    print(f\"Retrieved {len(weather_df)} hourly weather records.\")\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to delete all weather data from the weather_forecasts table\n",
    "def delete_all_weather_data(cursor):\n",
    "    \"\"\"\n",
    "    This function deletes the contents of the weather_forecasts table.\n",
    "    This ensures that there is no duplicate weather forecasts that can cause confusion.\n",
    "    Ensures only fresh forecast data is inserted and present each time the ELT pipeline runs.\n",
    "    \"\"\"\n",
    "    delete_weather_query = \"TRUNCATE TABLE weather_forecasts;\"\n",
    "    cursor.execute(delete_weather_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting austins weather data into the database\n",
    "def insert_weather_forecast_data(weather_df, connection):\n",
    "    \"\"\"Insert weather forecast data into the weather_forecasts table.\"\"\"\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO weather_forecasts (\n",
    "                forecast_time, forecast_temperature, forecast_temp_apparent, \n",
    "                forecast_humidity, rain_intensity, forecast_winds, weather_code, weather_icon\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        for row in weather_df.itertuples(index=False):\n",
    "            cursor.execute(insert_query, (\n",
    "                row.forecast_time, row.forecast_temperature, row.forecast_temp_apparent,\n",
    "                row.forecast_humidity, row.rain_intensity, row.forecast_winds, \n",
    "                row.weather_code, row.weather_icon\n",
    "            ))\n",
    "        connection.commit()\n",
    "        print(f\"Inserted {cursor.rowcount} weather forecast records.\")\n",
    "        cursor.close()\n",
    "    except Error as e:\n",
    "        print(f\"Error during weather data insertion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if we want this, but this is the visualization breakout that was in cynthias code\n",
    "def visualize_data(events_df):\n",
    "    \"\"\"\n",
    "    (optional) Create sample visualizations for events.\n",
    "    For example, plot number of events per venue and events by category.\n",
    "    \"\"\"\n",
    "    # group by venue_name and count unique events\n",
    "    event_counts = events_df.groupby('event_name').size().reset_index(name='count')\n",
    "    event_counts = event_counts.sort_values(by='count', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(event_counts['event_name'], event_counts['count'], color='skyblue')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Event')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Events Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query in order to get the event, venue and forecast details\n",
    "def get_event_venue_weather_details():\n",
    "    \"\"\"\n",
    "    Retrieves event, venue, and weather forecast info for the events\n",
    "    \"\"\"\n",
    "    conn = get_db_connection()\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        e.name AS Event, \n",
    "        e.start_date AS DateTime,\n",
    "        v.name AS Venue,\n",
    "        (wf.forecast_temperature * 9 / 5 + 32) AS Temp_F,\n",
    "        (wf.forecast_temp_apparent * 9 / 5 + 32) AS Feels_Like_F,\n",
    "        wf.forecast_humidity AS Humidity,\n",
    "        wf.rain_intensity AS Rain_mm,\n",
    "        ROUND((wf.forecast_winds * 0.621371), 2) AS Winds_mph,\n",
    "        wf.weather_icon\n",
    "    FROM events AS e\n",
    "    JOIN venues AS v on e.venue_id = v.venue_id\n",
    "    LEFT JOIN weather_forecasts AS wf \n",
    "        ON wf.forecast_time BETWEEN e.start_date - INTERVAL 29 MINUTE \n",
    "                            AND e.start_date + INTERVAL 30 MINUTE\n",
    "    WHERE e.start_date >= NOW() + INTERVAL -8 HOUR\n",
    "    ORDER BY e.start_date;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that prepares an email message with the event, venue and weather details for the week\n",
    "def send_notification(joined_df):\n",
    "    \"\"\"\n",
    "    Sends email notification with the event and weather forecast details for the time of the event\n",
    "    \n",
    "    Inputs:\n",
    "        joined_df: pandas df witih output of events and weather details\n",
    "        \n",
    "    Env Variables\n",
    "        Credentials for email account and recipients\n",
    "    \"\"\"\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "\n",
    "    # email account credentials\n",
    "    sender_email = os.getenv('SENDER_EMAIL')\n",
    "    sender_password = os.getenv('SENDER_PASSWORD')\n",
    "    recipient_emails = os.getenv('RECIPIENT_EMAILS')\n",
    "    print(f\"Sending email to: {recipient_emails}\")\n",
    "    # check for env credentials are valid and not empty\n",
    "    if not sender_email or not sender_password or not recipient_emails:\n",
    "        print(\"SMTP credentials or recipeint emails not provided or set in ENV variables.\")\n",
    "        return\n",
    "    \n",
    "    # email subject\n",
    "    subject = \"Upcoming Events and Weather Forecasts for San Diego\"\n",
    "\n",
    "    # convert DF to HTML table\n",
    "    if joined_df.empty:\n",
    "        body_html = \"<p>No upcoming events found.</p>\"\n",
    "    else:\n",
    "        # adds the part that goes to the github and grabs the picture.\n",
    "        def embed_icon(url):\n",
    "            if url:\n",
    "                return f'<img src=\"{url}\" width=\"40\" height=\"40\" alt=\"weather_icon\"/>'\n",
    "            else:\n",
    "                return \"No Icon Available\"\n",
    "        \n",
    "        joined_df['weather_icon'] = joined_df['weather_icon'].apply(embed_icon)\n",
    "\n",
    "        html_table = joined_df.to_html(index=False, border=1, escape=False)\n",
    "        body_html = f\"\"\"\n",
    "        <html>\n",
    "            <head>\n",
    "                <style>\n",
    "                    /* Add basic styling for the table */\n",
    "                    table {{\n",
    "                        border-collapse: collapse;\n",
    "                        width: 100%;\n",
    "                    }}\n",
    "                    th, td {{\n",
    "                        border: 1px solid #dddddd;\n",
    "                        text-align: left;\n",
    "                        padding: 8px;\n",
    "                    }}\n",
    "                    th {{\n",
    "                        background-color: #f2f2f2;\n",
    "                    }}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h2>Upcoming San Diego Events with Weather Forecasts</h2>\n",
    "                {html_table}\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    \n",
    "    # create the actual message headers subject, from, to\n",
    "    msg = MIMEMultipart('alternative')\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = recipient_emails\n",
    "\n",
    "    # attach the message body\n",
    "    msg.attach(MIMEText(body_html, 'html'))\n",
    "\n",
    "    # connect gmail server and send email\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            # start TLS for security\n",
    "            server.starttls()\n",
    "            #login to email account\n",
    "            server.login(sender_email, sender_password)\n",
    "            #send email and split recipients by comma\n",
    "            server.sendmail(sender_email, recipient_emails.split(','), msg.as_string())\n",
    "        print(\"Email sent successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL database\n",
      "Requesting Ticketmaster events...\n",
      "Pulled 57 events from API.\n",
      "Deleted 13 past events.\n",
      "Venues inserted/updated successfully.\n",
      "Events inserted/updated successfully.\n",
      "Requesting Tomorrow.io weather forecast data...\n",
      "Retrieved 120 hourly weather records.\n",
      "Inserted 1 weather forecast records.\n",
      "Connected to MySQL database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graha\\AppData\\Local\\Temp\\ipykernel_64432\\3198284887.py:26: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending email to: grahamward92@gmail.com,grahamward@me.com\n",
      "Email sent successfully.\n",
      "ETL pipeline executed successfully.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    connection = get_db_connection()\n",
    "    if not connection:\n",
    "        print(\"Exiting due to database connection error.\")\n",
    "        return\n",
    "\n",
    "    # Process events and venues\n",
    "    try:\n",
    "        events_df, venues_df = get_events_and_venues_data()\n",
    "        if not events_df.empty and not venues_df.empty:\n",
    "            insert_events_and_venues(events_df, venues_df, connection)\n",
    "        else:\n",
    "            print(\"No events/venues data to insert.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during events/venues processing: {e}\")\n",
    "    \n",
    "    # Process weather forecasts\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        delete_all_weather_data(cursor)\n",
    "        connection.commit()\n",
    "        weather_df = get_weather_forecast_data()\n",
    "        if not weather_df.empty:\n",
    "            insert_weather_forecast_data(weather_df, connection)\n",
    "        else:\n",
    "            print(\"No weather forecast data to insert.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during weather forecast processing: {e}\")\n",
    "    \n",
    "    connection.close()\n",
    "    \n",
    "    # Retrieve joined data and send notification email\n",
    "    try:\n",
    "        joined_df = get_event_venue_weather_details()\n",
    "        send_notification(joined_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending notification email: {e}\")\n",
    "    \n",
    "    print(\"ETL pipeline executed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
